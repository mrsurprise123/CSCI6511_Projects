Description:
1. value iteration
After calculating all the results, select the largest one for each iteration
2. policy iteration
The original policy is go left first, then calculating utilities until convergence. Then update the
policy by one_step look_ahead. Repeat steps until converges.
How to run:
Run the Project3_MDPs.py, input the filename with path and iteration times